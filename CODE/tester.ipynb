{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  18 of 18 completed\n",
            "[*********************100%***********************]  18 of 18 completed\n",
            "[*********************100%***********************]  18 of 18 completed\n",
            "                 0\n",
            "2.671890e-01  meta\n",
            "3.660338e-01  adbe\n",
            "3.868138e-17   amd\n",
            "5.234701e-02  csco\n",
            "9.149450e-02  fisv\n",
            "3.795461e-16   ibm\n",
            "8.256835e-17   ale\n",
            "2.428266e-02  lrcx\n",
            "6.299956e-16  jazz\n",
            "3.476313e-02    mu\n",
            "3.241777e-16  orcl\n",
            "1.649107e-16  qcom\n",
            "1.020142e-17   txn\n",
            "2.207295e-16  nvda\n",
            "2.249614e-17   fis\n",
            "7.854478e-16   crm\n",
            "1.005672e-16  eqix\n",
            "1.638899e-01  vrsk\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "import gspread as gs\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "from gspread_formatting.dataframe import format_with_dataframe\n",
        "from scipy.optimize import minimize\n",
        "import yfinance as yf\n",
        "import jupytab\n",
        "\n",
        "def google_caller():\n",
        "    gc = gs.service_account(filename='dva-api-384400-c063824c0207.json')\n",
        "    gc\n",
        " \n",
        "    sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/1nS8WRaVB5S2aaxMiFpVHxSrEE12lx6TGs_WyAkcUSzU/edit?usp=sharing')\n",
        "    ws = sh.worksheet('Form Responses 1')\n",
        " \n",
        "    df = pd.DataFrame(ws.get_all_records())\n",
        " \n",
        "    df = df[['Timestamp', 'Risk Assessment Score']].rename(columns={'Timestamp':'time', 'Risk Assessment Score':'score'})\n",
        "    df = df.sort_values(by='time', ascending=False).head(1)\n",
        "    return df\n",
        " \n",
        " \n",
        "df = google_caller()\n",
        "def ticker_picker(df):\n",
        "    if df['score'].iloc[0] <= 12:\n",
        "        tickers = ['aapl','adbe','amd','csco', 'fisv', 'ibm', 'intc', 'lrcx', 'msft', 'mu', 'orcl', 'qcom', 'txn', 'nvda', 'fis', 'crm', 'avgo', 'now']\n",
        " \n",
        "    elif (df['score'].iloc[0] > 12) & (df['score'].iloc[0] <= 20):\n",
        "        tickers = ['csgp','mdu','amd','csco', 'lly', 'ibm', 'intc', 'wba', 'isrg', 'pep', 'orcl', 'qcom', 'aciw', 'nvda', 'qlys', 'crm', 'cost', 'now']\n",
        " \n",
        "    elif (df['score'].iloc[0] > 20) & (df['score'].iloc[0] <= 28):\n",
        "        tickers = ['aapl','adbe','amd','csco', 'fisv', 'ibm', 'intc', 'lrcx', 'msft', 'mu', 'orcl', 'nbix', 'txn', 'nvda', 'fis', 'crm', 'avgo', 'saic']\n",
        " \n",
        "    elif (df['score'].iloc[0] > 29) & (df['score'].iloc[0] <= 34):\n",
        "        tickers = ['dci','adbe','mrcy','wtrg', 'fisv', 'ibm', 'axs', 'lrcx', 'msft', 'bros', 'orcl', 'pypl', 'txn', 'amrc', 'fis', 'crm', 'chgg', 'now']\n",
        " \n",
        "    elif (df['score'].iloc[0] > 35):\n",
        "        tickers = ['meta','adbe','amd','csco', 'fisv', 'ibm', 'ale', 'lrcx', 'jazz', 'mu', 'orcl', 'qcom', 'txn', 'nvda', 'fis', 'crm', 'eqix', 'vrsk']\n",
        "    \n",
        "    stock_data = yf.download(tickers,start='2017-01-1', end='2018-12-1')\n",
        "    stock_data = stock_data.dropna()\n",
        "    stocks = stock_data['Adj Close']\n",
        "    return stocks, tickers\n",
        "ticker_picker(df)\n",
        " \n",
        " \n",
        "google_df = google_caller()\n",
        "stocks = ticker_picker(google_df)[0]\n",
        "tickers = ticker_picker(google_df)[1]\n",
        "\n",
        "def efficient_frontier_calculator(stocks):\n",
        "    np.random.seed(100)\n",
        " \n",
        "    log_ret = np.log(stocks/stocks.shift(1))\n",
        "    log_ret.head()\n",
        " \n",
        "    w_random = np.random.random(18)\n",
        "    weights = np.array(w_random)\n",
        "    # print(weights/np.sum(weights))\n",
        "    # print('\\n\\n')\n",
        " \n",
        "    weight_log = log_ret.mean() * weights\n",
        "    expected_returns = np.sum(weight_log) *252\n",
        "    # print(expected_returns)\n",
        "    # print('\\n')\n",
        " \n",
        "    transformed_weight = weights.T\n",
        "    day_scale = 252\n",
        "    expected_volatility = np.sqrt(np.dot(transformed_weight, np.dot(log_ret.cov() * day_scale, weights)))\n",
        "    # print(expected_volatility)\n",
        "    # print('\\n')\n",
        " \n",
        "    sharpe_ratio = expected_returns/expected_volatility\n",
        "    # print(sharpe_ratio)\n",
        "    return log_ret, weights\n",
        "log_ret, efc = efficient_frontier_calculator(stocks)\n",
        "\n",
        "def weight_methodology(stocks, log_ret, weights):\n",
        "    num_of_stocks = len(stocks.columns)\n",
        "    all_weights = np.zeros((15000, num_of_stocks))\n",
        "    ret_arr = np.zeros(15000)\n",
        "    vol_arr = np.zeros(15000)\n",
        "    sharpe_arr = np.zeros(15000)\n",
        "    day_len = 252\n",
        "    w_transform = weights.T\n",
        "    retention_mean = log_ret.mean()\n",
        " \n",
        "    for indicator in range(15000):\n",
        " \n",
        "        weights = np.array(np.random.random(18))\n",
        "        all_weights[indicator,:] = weights / np.sum(weights)\n",
        "        ret_arr[indicator] = np.sum((retention_mean * weights) * day_len)\n",
        "        vol_arr[indicator] = np.sqrt(np.dot(w_transform, np.dot(log_ret.cov() * day_len, weights)))\n",
        "        sharpe_arr[indicator] = ret_arr[indicator]/vol_arr[indicator]\n",
        "    return weights\n",
        "w_methodology = weight_methodology(stocks, log_ret, efc)\n",
        "\n",
        "\n",
        "def get_rvs(w_methodology):\n",
        "    weights = np.array(w_methodology)\n",
        "    ret = np.sum(log_ret.mean() * weights) * 252\n",
        "    vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 252, weights)))\n",
        "    sr = ret/vol\n",
        "    return np.array([ret,vol,sr])\n",
        " \n",
        "def negative_sharpe(w_methodology):\n",
        "    rvs_return = get_rvs(w_methodology)[2]\n",
        "    neg_rvs = rvs_return * -1\n",
        "    return neg_rvs\n",
        " \n",
        "def check_sum(w_methodology):\n",
        "    sum_checker = np.sum(w_methodology) - 1\n",
        " \n",
        "    return sum_checker\n",
        " \n",
        "opt_results = minimize(negative_sharpe, [0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555,0.0555], method = 'SLSQP', bounds=[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)], constraints=({'type':'eq','fun': check_sum}))\n",
        " \n",
        " \n",
        "weights = opt_results.x\n",
        " \n",
        "portfolio_df = pd.DataFrame(tickers)\n",
        " \n",
        "portfolio_df['weights'] = weights\n",
        "portfolio_df = portfolio_df.rename(columns={0:'ticker'})\n",
        "output_df = pd.DataFrame(tickers[:18], weights[:18])\n",
        "print(output_df)\n",
        "\n",
        "#final_df\n",
        "tables = jupytab.Tables()\n",
        "\n",
        "\n",
        "# # Example 1: Static data: it will never change on the Tableau side:\n",
        "# static_df = dynamic_df()\n",
        "# tables['static'] = jupytab.DataFrameTable('A static table', dataframe=static_df)\n",
        "\n",
        "# Example 2: Dynamic data: a new DataFrame is generated whenever Extract is requested on Tableau's side:\n",
        "tables['portfoliobalanced1'] = jupytab.DataFrameTable('PortfolioBalanced1', dataframe=output_df, include_index=True)\n",
        "\n",
        "# def multiply(my_first_number, my_second_number):\n",
        "#     return my_first_number * my_second_number\n",
        "    \n",
        "# functions = jupytab.Functions() # Publication-ready functions contained by this notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\"id\": \"portfoliobalanced1\", \"alias\": \"PortfolioBalanced1\", \"columns\": [{\"id\": \"index\", \"dataType\": \"float\"}, {\"id\": \"0\", \"dataType\": \"string\"}]}]\n"
          ]
        }
      ],
      "source": [
        "# GET /schema\n",
        "tables.render_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not Available outside jupytab context\n"
          ]
        }
      ],
      "source": [
        "# GET /data\n",
        "try:\n",
        "    tables.render_data(REQUEST)\n",
        "except NameError:\n",
        "    print(\"Not Available outside jupytab context\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not available outside jupytab context\n"
          ]
        }
      ],
      "source": [
        "# POST /evaluate\n",
        "try:\n",
        "    functions.render_evaluate(REQUEST)\n",
        "except NameError:\n",
        "    print(\"Not available outside jupytab context\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.16 ('jupytab_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "a942b14cd2925055dfb4950ec7774dd9d3e31fce316b08b234b040b5686966ca"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
